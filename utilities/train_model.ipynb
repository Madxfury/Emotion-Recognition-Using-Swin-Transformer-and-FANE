{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61136cd8-ffb9-49d5-ade1-c32062346133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cpu\n",
      "Found 13563 training and 2160 validation images.\n",
      "Class Mapping: {'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Neutral': 4, 'Sad': 5, 'Surprise': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ba0ea447-ac06-4d07-8612-0a5c4725bb0b)')' thrown while requesting HEAD https://huggingface.co/timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k/resolve/main/model.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PHASE 1: Training Classifier Head ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Head Train 1/5: 100%|███████████████████████████████████████████████████████████████████████| 424/424 [06:16<00:00,  1.12it/s]\n",
      "Head Val 1/5: 100%|███████████████████████████████████████████████████████████████████████████| 68/68 [01:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc=0.4750, Val Acc=0.5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Head Train 2/5: 100%|███████████████████████████████████████████████████████████████████████| 424/424 [06:22<00:00,  1.11it/s]\n",
      "Head Val 2/5: 100%|███████████████████████████████████████████████████████████████████████████| 68/68 [01:03<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Acc=0.5430, Val Acc=0.6153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Head Train 3/5: 100%|███████████████████████████████████████████████████████████████████████| 424/424 [06:41<00:00,  1.06it/s]\n",
      "Head Val 3/5: 100%|███████████████████████████████████████████████████████████████████████████| 68/68 [01:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Acc=0.5685, Val Acc=0.6384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Head Train 4/5: 100%|███████████████████████████████████████████████████████████████████████| 424/424 [06:24<00:00,  1.10it/s]\n",
      "Head Val 4/5: 100%|███████████████████████████████████████████████████████████████████████████| 68/68 [00:58<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Acc=0.5884, Val Acc=0.6306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Head Train 5/5: 100%|███████████████████████████████████████████████████████████████████████| 424/424 [06:28<00:00,  1.09it/s]\n",
      "Head Val 5/5: 100%|███████████████████████████████████████████████████████████████████████████| 68/68 [01:02<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Acc=0.6063, Val Acc=0.6745\n",
      "\n",
      "--- PHASE 2: Fine-Tuning Entire Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Train 6/15: 100%|██████████████████████████████████████████████████████████████████████| 424/424 [23:03<00:00,  3.26s/it]\n",
      "Full Val 6/15: 100%|██████████████████████████████████████████████████████████████████████████| 68/68 [01:09<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Acc=0.6575, Val Acc=0.7338\n",
      "⭐ Saved new best model with Validation Accuracy: 0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Train 7/15: 100%|██████████████████████████████████████████████████████████████████████| 424/424 [22:14<00:00,  3.15s/it]\n",
      "Full Val 7/15: 100%|██████████████████████████████████████████████████████████████████████████| 68/68 [00:57<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Acc=0.7096, Val Acc=0.7833\n",
      "⭐ Saved new best model with Validation Accuracy: 0.7833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Train 8/15: 100%|██████████████████████████████████████████████████████████████████████| 424/424 [20:34<00:00,  2.91s/it]\n",
      "Full Val 8/15: 100%|██████████████████████████████████████████████████████████████████████████| 68/68 [00:56<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Acc=0.7508, Val Acc=0.8250\n",
      "⭐ Saved new best model with Validation Accuracy: 0.8250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Train 9/15: 100%|██████████████████████████████████████████████████████████████████████| 424/424 [20:48<00:00,  2.94s/it]\n",
      "Full Val 9/15: 100%|██████████████████████████████████████████████████████████████████████████| 68/68 [00:57<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Acc=0.7832, Val Acc=0.8560\n",
      "⭐ Saved new best model with Validation Accuracy: 0.8560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Train 10/15: 100%|█████████████████████████████████████████████████████████████████████| 424/424 [21:02<00:00,  2.98s/it]\n",
      "Full Val 10/15: 100%|█████████████████████████████████████████████████████████████████████████| 68/68 [00:57<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Acc=0.8195, Val Acc=0.8704\n",
      "⭐ Saved new best model with Validation Accuracy: 0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Train 11/15: 100%|█████████████████████████████████████████████████████████████████████| 424/424 [21:02<00:00,  2.98s/it]\n",
      "Full Val 11/15: 100%|█████████████████████████████████████████████████████████████████████████| 68/68 [00:57<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Acc=0.8382, Val Acc=0.8847\n",
      "⭐ Saved new best model with Validation Accuracy: 0.8847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Train 12/15: 100%|█████████████████████████████████████████████████████████████████████| 424/424 [22:55<00:00,  3.24s/it]\n",
      "Full Val 12/15: 100%|█████████████████████████████████████████████████████████████████████████| 68/68 [01:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Acc=0.8567, Val Acc=0.8898\n",
      "⭐ Saved new best model with Validation Accuracy: 0.8898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Train 13/15: 100%|█████████████████████████████████████████████████████████████████████| 424/424 [22:00<00:00,  3.12s/it]\n",
      "Full Val 13/15: 100%|█████████████████████████████████████████████████████████████████████████| 68/68 [00:57<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Acc=0.8771, Val Acc=0.9060\n",
      "⭐ Saved new best model with Validation Accuracy: 0.9060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Train 14/15: 100%|█████████████████████████████████████████████████████████████████████| 424/424 [21:27<00:00,  3.04s/it]\n",
      "Full Val 14/15: 100%|█████████████████████████████████████████████████████████████████████████| 68/68 [00:58<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Acc=0.8900, Val Acc=0.8958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Train 15/15: 100%|█████████████████████████████████████████████████████████████████████| 424/424 [21:29<00:00,  3.04s/it]\n",
      "Full Val 15/15: 100%|█████████████████████████████████████████████████████████████████████████| 68/68 [00:57<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Acc=0.8952, Val Acc=0.9106\n",
      "⭐ Saved new best model with Validation Accuracy: 0.9106\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# =====================================================================\n",
    "# 1. Ensure images are always RGB\n",
    "# =====================================================================\n",
    "def rgb_converter(img):\n",
    "    return img.convert(\"RGB\")\n",
    "\n",
    "# =====================================================================\n",
    "# 2. Corrected Model Definition\n",
    "# =====================================================================\n",
    "class CustomSwinTransformer(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=7):\n",
    "        super(CustomSwinTransformer, self).__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            'swin_base_patch4_window7_224',\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0  # remove original classifier\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.backbone.num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# =====================================================================\n",
    "# 3. Training and Validation Functions\n",
    "# =====================================================================\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device, desc=\"Training\"):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for inputs, labels in tqdm(dataloader, desc=desc):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == labels)\n",
    "        total += labels.size(0)\n",
    "    return running_loss / total, correct.double() / total\n",
    "\n",
    "def validate_model(model, dataloader, criterion, device, desc=\"Validating\"):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=desc):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels)\n",
    "            total += labels.size(0)\n",
    "    return running_loss / total, correct.double() / total\n",
    "\n",
    "# =====================================================================\n",
    "# 4. Main (for Jupyter)\n",
    "# =====================================================================\n",
    "\n",
    "# Replace with your actual dataset paths\n",
    "FANE_TRAIN_DATA_PATH = \"/Users/sanskarparab/CC Emotion Detection /Facial-Expression-Recognition-FER-for-Mental-Health-Detection-/traintestsplit/train\"\n",
    "FANE_VAL_DATA_PATH = \"/Users/sanskarparab/CC Emotion Detection /Facial-Expression-Recognition-FER-for-Mental-Health-Detection-/traintestsplit/val\"\n",
    "MODEL_SAVE_PATH = \"/Users/sanskarparab/CC Emotion Detection /Facial-Expression-Recognition-FER-for-Mental-Health-Detection-/Models/Swin_FANE_Best_Model.pth\"\n",
    "\n",
    "NUM_CLASSES = 7\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {DEVICE}\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    rgb_converter,\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=FANE_TRAIN_DATA_PATH, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=FANE_VAL_DATA_PATH, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Found {len(train_dataset)} training and {len(val_dataset)} validation images.\")\n",
    "print(\"Class Mapping:\", train_dataset.class_to_idx)\n",
    "\n",
    "# Create Model\n",
    "model = CustomSwinTransformer(pretrained=True, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Phase 1: Train Classifier Head ---\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = optim.AdamW(model.classifier.parameters(), lr=5e-4)\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(\"\\n--- PHASE 1: Training Classifier Head ---\")\n",
    "for epoch in range(5):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE, desc=f\"Head Train {epoch+1}/5\")\n",
    "    val_loss, val_acc = validate_model(model, val_loader, criterion, DEVICE, desc=f\"Head Val {epoch+1}/5\")\n",
    "    print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")\n",
    "\n",
    "# --- Phase 2: Fine-tune Whole Model ---\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "print(\"\\n--- PHASE 2: Fine-Tuning Entire Model ---\")\n",
    "for epoch in range(5, 15):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE, desc=f\"Full Train {epoch+1}/15\")\n",
    "    val_loss, val_acc = validate_model(model, val_loader, criterion, DEVICE, desc=f\"Full Val {epoch+1}/15\")\n",
    "    print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"⭐ Saved new best model with Validation Accuracy: {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daaffd34-d49f-4cc7-abb1-ade265e53845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-1.0.21-py3-none-any.whl.metadata (62 kB)\n",
      "Requirement already satisfied: torch in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from timm) (2.9.0)\n",
      "Requirement already satisfied: torchvision in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from timm) (0.24.0)\n",
      "Requirement already satisfied: pyyaml in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from timm) (0.35.3)\n",
      "Requirement already satisfied: safetensors in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: filelock in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface_hub->timm) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface_hub->timm) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface_hub->timm) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2025.10.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from jinja2->torch->timm) (3.0.3)\n",
      "Requirement already satisfied: numpy in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/sanskarparab/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from torchvision->timm) (11.3.0)\n",
      "Downloading timm-1.0.21-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: timm\n",
      "Successfully installed timm-1.0.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf0b7a0-9aa3-41ea-9acb-b53baa414cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 (pyenv)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
